"""ì¦ë¶„ ì—…ë°ì´íŠ¸ ì„œë¹„ìŠ¤."""

import logging
import shutil
import time
from datetime import datetime
from typing import List, Dict, Optional, Tuple
import pandas as pd

from core.ports.file_reader_port import FileReaderPort
from core.ports.corp_code_port import CorpCodePort
from core.ports.financial_statement_port import FinancialStatementPort
from core.ports.storage_port import StoragePort
from core.services.data_processing_service import DataProcessingService
from core.domain.models.financial_statement import ReportType

logger = logging.getLogger(__name__)


class IncrementalUpdateService:
    """ëˆ„ë½ëœ ë¶„ê¸° ë°ì´í„°ë¥¼ ì¦ë¶„ ì—…ë°ì´íŠ¸í•˜ëŠ” ì„œë¹„ìŠ¤."""
    
    # ë¶„ê¸° â†’ ReportType ë§¤í•‘
    QUARTER_TO_REPORT = {
        1: ReportType.Q1,
        2: ReportType.SEMI_ANNUAL,
        3: ReportType.Q3,
        4: ReportType.ANNUAL,
    }
    
    # ì²˜ë¦¬ ëŒ€ìƒ ì‹œíŠ¸ (ë¶„ê¸°ë³„ë§Œ)
    QUARTERLY_SHEETS = ["ë§¤ì¶œì•¡_ë¶„ê¸°", "ì˜ì—…ì´ìµ_ë¶„ê¸°", "ë‹¹ê¸°ìˆœì´ìµ_ë¶„ê¸°"]
    
    def __init__(
        self,
        file_reader: FileReaderPort,
        corp_code_port: CorpCodePort,
        financial_port: FinancialStatementPort,
        storage_port: StoragePort,
        processing_service: DataProcessingService,
        max_api_calls: int = 9950
    ):
        self._file_reader = file_reader
        self._corp_code_port = corp_code_port
        self._financial_port = financial_port
        self._storage_port = storage_port
        self._processing_service = processing_service
        
        self._max_api_calls = max_api_calls
        self._current_api_calls = 0

    def update_missing_quarters(
        self,
        file_path: str,
        target_year: int,
        target_quarter: int,
        auto_backup: bool = True
    ) -> None:
        """íŠ¹ì • ë¶„ê¸°ì˜ ëˆ„ë½ëœ ë°ì´í„°ë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
        
        Args:
            file_path: ì—…ë°ì´íŠ¸í•  ì—‘ì…€ íŒŒì¼ ê²½ë¡œ
            target_year: ëŒ€ìƒ ì—°ë„ (ì˜ˆ: 2025)
            target_quarter: ëŒ€ìƒ ë¶„ê¸° (1, 2, 3, 4)
            auto_backup: ìë™ ë°±ì—… ì—¬ë¶€
        """
        target_period = f"{target_year}.{target_quarter}Q"
        logger.info(f"ğŸš€ ì¦ë¶„ ì—…ë°ì´íŠ¸ ì‹œì‘: {target_period} (íŒŒì¼: {file_path})")
        
        # 1. íŒŒì¼ ë°±ì—…
        if auto_backup:
            self._backup_file(file_path)
            
        # 2. ê¸°ì¡´ íŒŒì¼ ì½ê¸°
        logger.info("ê¸°ì¡´ íŒŒì¼ ì½ëŠ” ì¤‘...")
        try:
            existing_sheets = self._file_reader.read_excel_with_sheets(file_path)
        except FileNotFoundError:
            logger.error(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
            return

        # 3. ëˆ„ë½ ê¸°ì—… ì°¾ê¸°
        missing_companies = self.find_missing_companies(existing_sheets, target_period)
        if not missing_companies:
            logger.info(f"âœ¨ ëˆ„ë½ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ({target_period})")
            return
            
        logger.info(f"ğŸ“‹ ëˆ„ë½ ê¸°ì—… {len(missing_companies)}ê°œ ë°œê²¬: {missing_companies[:5]}...")
        
        # 4. ë°ì´í„° ìˆ˜ì§‘ (ì—°ë„ ì „ì²´)
        collected_data = []
        processed_count = 0
        
        for idx, company_name in enumerate(missing_companies, 1):
            # API í˜¸ì¶œ ì œí•œ ì²´í¬
            if self._current_api_calls >= self._max_api_calls:
                logger.warning(f"âš ï¸ API í˜¸ì¶œ ì œí•œ ë„ë‹¬! ({self._current_api_calls}/{self._max_api_calls})")
                logger.info("ì‘ì—…ì„ ì¤‘ë‹¨í•˜ê³  í˜„ì¬ê¹Œì§€ ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.")
                break
                
            logger.info(f"[{idx}/{len(missing_companies)}] {company_name} ë°ì´í„° ìˆ˜ì§‘ ì¤‘... (API í˜¸ì¶œ: {self._current_api_calls})")
            
            try:
                # ê¸°ì—… ì½”ë“œ ì¡°íšŒ
                corp_code = self._corp_code_port.get_code(company_name)
                if not corp_code:
                    logger.warning(f"  âŒ ê¸°ì—… ì½”ë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {company_name}")
                    continue
                
                # í•´ë‹¹ ì—°ë„ ì „ì²´ ë°ì´í„° ìˆ˜ì§‘
                company_data = self._collect_year_for_company(company_name, corp_code, target_year)
                
                if company_data:
                    collected_data.extend(company_data)
                    processed_count += 1
                    
            except Exception as e:
                logger.error(f"  âŒ {company_name} ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
                continue
        
        if not collected_data:
            logger.warning("ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        # 5. ìˆ˜ì§‘ëœ ë°ì´í„° ë³€í™˜ (Wide Format)
        logger.info(f"ğŸ“Š ìˆ˜ì§‘ëœ ë°ì´í„° ë³€í™˜ ì¤‘... ({len(collected_data)}ê°œ í•­ëª©)")
        new_sheets = self._convert_to_wide_format(collected_data)
        
        # 6. ë³‘í•© (ê¸°ì¡´ ë°ì´í„° ìš°ì„ )
        logger.info("ğŸ”„ ë°ì´í„° ë³‘í•© ì¤‘...")
        merged_sheets = self.merge_quarterly_data(existing_sheets, new_sheets)
        
        # 7. ì €ì¥
        logger.info(f"ğŸ’¾ ê²°ê³¼ ì €ì¥ ì¤‘: {file_path}")
        self._storage_port.save_excel_with_sheets(merged_sheets, file_path)
        logger.info(f"âœ… ì—…ë°ì´íŠ¸ ì™„ë£Œ! (ì²˜ë¦¬ëœ ê¸°ì—…: {processed_count}ê°œ, ì´ API í˜¸ì¶œ: {self._current_api_calls}íšŒ)")

    def find_missing_companies(
        self,
        sheets: Dict[str, pd.DataFrame],
        target_period: str
    ) -> List[str]:
        """íŠ¹ì • ë¶„ê¸°ê°€ ëˆ„ë½ëœ ê¸°ì—… ëª©ë¡ì„ ì°¾ìŠµë‹ˆë‹¤."""
        # ë§¤ì¶œì•¡_ë¶„ê¸° ì‹œíŠ¸ ê¸°ì¤€
        revenue_sheet = sheets.get("ë§¤ì¶œì•¡_ë¶„ê¸°")
        if revenue_sheet is None:
            logger.warning("'ë§¤ì¶œì•¡_ë¶„ê¸°' ì‹œíŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. ëª¨ë“  ê¸°ì—…ì„ ëŒ€ìƒìœ¼ë¡œ ê°„ì£¼í•  ìˆ˜ ì—†ìœ¼ë¯€ë¡œ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜.")
            return []
        
        missing = []
        
        # ì»¬ëŸ¼ ìì²´ê°€ ì—†ëŠ” ê²½ìš°: ëª¨ë“  ê¸°ì—…ì´ ëˆ„ë½
        if target_period not in revenue_sheet.columns:
            logger.info(f"'{target_period}' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. ëª¨ë“  ê¸°ì—…ì„ ìˆ˜ì§‘ ëŒ€ìƒìœ¼ë¡œ í•©ë‹ˆë‹¤.")
            return revenue_sheet.index.tolist()
            
        # ì»¬ëŸ¼ì€ ìˆì§€ë§Œ ê°’ì´ NaNì¸ ê²½ìš°
        for company in revenue_sheet.index:
            if pd.isna(revenue_sheet.loc[company, target_period]):
                missing.append(company)
        
        return missing

    def _collect_year_for_company(
        self,
        company_name: str,
        corp_code: str,
        year: int
    ) -> List[Dict]:
        """íŠ¹ì • ê¸°ì—…ì˜ í•´ë‹¹ ì—°ë„ ì „ì²´(1Q~4Q) ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤."""
        statements = []
        
        # 1Q, ë°˜ê¸°, 3Q, ì—°ê°„ ë³´ê³ ì„œ ìˆœì°¨ ìˆ˜ì§‘
        for q_num in [1, 2, 3, 4]:
            report_type = self.QUARTER_TO_REPORT[q_num]
            
            # API í˜¸ì¶œ (ì—¬ê¸°ì„œ ì¹´ìš´íŒ…ì€ ì •í™•íˆ í•˜ë ¤ë©´ FinancialPortë¥¼ ë˜í•‘í•˜ê±°ë‚˜
            # Adapterê°€ í˜¸ì¶œ ì—¬ë¶€ë¥¼ ì•Œë ¤ì¤˜ì•¼ í•¨. í˜„ì¬ëŠ” ë‹¨ìˆœí™”ë¥¼ ìœ„í•´ ìš”ì²­ ì‹œë§ˆë‹¤ ì¦ê°€ë¡œ ê°€ì •í•˜ë˜,
            # ì‹¤ì œë¡œëŠ” ìºì‹œ íˆíŠ¸ ì‹œ í˜¸ì¶œì´ ì•ˆ ì¼ì–´ë‚  ìˆ˜ ìˆìŒ. 
            # ë³´ìˆ˜ì ìœ¼ë¡œ ìš”ì²­ ì‹œë§ˆë‹¤ ì¹´ìš´íŠ¸ ì¦ê°€)
            
            # TODO: ì •í™•í•œ ì¹´ìš´íŒ…ì„ ìœ„í•´ FinancialPortê°€ í˜¸ì¶œ ì—¬ë¶€ë¥¼ ë°˜í™˜í•˜ë„ë¡ ê°œì„  í•„ìš”
            # í˜„ì¬ëŠ” ìš”ì²­ ì‹œë§ˆë‹¤ ë¬´ì¡°ê±´ ì¹´ìš´íŠ¸ ì¦ê°€ (ë³´ìˆ˜ì  ì ‘ê·¼)
            self._current_api_calls += 1
            
            time.sleep(0.1) # ë¶€í•˜ ë°©ì§€
            stmt = self._financial_port.get_financial_statement(corp_code, year, report_type)
            statements.append(stmt)

        # ë¶„ê¸° ì‹¤ì  ê³„ì‚°
        # statements ë¦¬ìŠ¤íŠ¸ ìˆœì„œ: [1Q, Semi, 3Q, Annual] (Noneì¼ ìˆ˜ ìˆìŒ)
        metrics = self._processing_service.calculate_quarterly_performance(
            statements[0], statements[1], statements[2], statements[3]
        )
        
        # Long Format ë³€í™˜
        data_list = []
        for q in ["1Q", "2Q", "3Q", "4Q"]:
            m = metrics.metrics_by_quarter.get(q)
            if m:
                data_list.append({
                    "ê¸°ì—…ëª…": company_name,
                    "ì—°ë„": year,
                    "ë¶„ê¸°": q,
                    "ë§¤ì¶œì•¡": m.revenue,
                    "ì˜ì—…ì´ìµ": m.operating_profit,
                    "ë‹¹ê¸°ìˆœì´ìµ": m.net_income
                })
        
        return data_list

    def _convert_to_wide_format(self, data_list: List[Dict]) -> Dict[str, pd.DataFrame]:
        """Long Format ë°ì´í„°ë¥¼ Wide Format(ì‹œíŠ¸ë³„)ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
        if not data_list:
            return {}
            
        df = pd.DataFrame(data_list)
        df["ê¸°ê°„"] = df["ì—°ë„"].astype(str) + "." + df["ë¶„ê¸°"]
        
        # ë‹¨ìœ„ ë³€í™˜ (ë°±ë§Œì›)
        for col in ["ë§¤ì¶œì•¡", "ì˜ì—…ì´ìµ", "ë‹¹ê¸°ìˆœì´ìµ"]:
            if col in df.columns:
                df[col] = (df[col] / 1_000_000).round(0)
        
        sheets = {}
        if not df.empty:
            sheets["ë§¤ì¶œì•¡_ë¶„ê¸°"] = df.pivot(index="ê¸°ì—…ëª…", columns="ê¸°ê°„", values="ë§¤ì¶œì•¡")
            sheets["ì˜ì—…ì´ìµ_ë¶„ê¸°"] = df.pivot(index="ê¸°ì—…ëª…", columns="ê¸°ê°„", values="ì˜ì—…ì´ìµ")
            sheets["ë‹¹ê¸°ìˆœì´ìµ_ë¶„ê¸°"] = df.pivot(index="ê¸°ì—…ëª…", columns="ê¸°ê°„", values="ë‹¹ê¸°ìˆœì´ìµ")
            
        return sheets

    def merge_quarterly_data(
        self,
        existing_sheets: Dict[str, pd.DataFrame],
        new_sheets: Dict[str, pd.DataFrame]
    ) -> Dict[str, pd.DataFrame]:
        """ê¸°ì¡´ ë°ì´í„°ì™€ ìƒˆ ë°ì´í„°ë¥¼ ë³‘í•©í•©ë‹ˆë‹¤ (ê¸°ì¡´ ë°ì´í„° ìš°ì„ )."""
        merged_sheets = {}
        
        for sheet_name in existing_sheets.keys():
            existing_df = existing_sheets[sheet_name]
            
            # ë¶„ê¸°ë³„ ì‹œíŠ¸ê°€ ì•„ë‹ˆë©´ ê·¸ëŒ€ë¡œ ìœ ì§€
            if sheet_name not in self.QUARTERLY_SHEETS:
                merged_sheets[sheet_name] = existing_df
                continue
            
            new_df = new_sheets.get(sheet_name)
            if new_df is None or new_df.empty:
                merged_sheets[sheet_name] = existing_df
                continue
            
            # ê¸°ì¡´ ë°ì´í„° ìš°ì„  ë³‘í•©: existingì˜ NaNë§Œ newë¡œ ì±„ì›€
            # combine_firstëŠ” í˜¸ì¶œí•˜ëŠ” ê°ì²´(existing)ê°€ ìš°ì„ ì„
            merged_df = existing_df.combine_first(new_df)
            
            # ì •ë ¬
            merged_df = merged_df.sort_index(axis=0)  # ê¸°ì—…ëª… ì •ë ¬
            
            # ì»¬ëŸ¼ ì •ë ¬ (ìì—° ì •ë ¬: 2024.1Q, 2024.2Q, ...)
            def sort_key(col):
                try:
                    # ì»¬ëŸ¼ëª…ì´ ë¬¸ìì—´ì´ ì•„ë‹ˆê±°ë‚˜ í˜•ì‹ì´ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ
                    col_str = str(col)
                    if '.' in col_str:
                        year, quarter = col_str.split('.')
                        quarter_num = int(quarter[0])  # "1Q" -> 1
                        return (int(year), quarter_num)
                    return (0, 0)
                except:
                    return (0, 0)
            
            sorted_cols = sorted(merged_df.columns, key=sort_key)
            merged_df = merged_df[sorted_cols]
            
            merged_sheets[sheet_name] = merged_df
        
        return merged_sheets

    def _backup_file(self, file_path: str) -> str:
        """íŒŒì¼ì„ ë°±ì—…í•©ë‹ˆë‹¤."""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_path = file_path.replace(".xlsx", f"_backup_{timestamp}.xlsx")
        try:
            shutil.copy2(file_path, backup_path)
            logger.info(f"ğŸ“¦ ë°±ì—… ì™„ë£Œ: {backup_path}")
            return backup_path
        except Exception as e:
            logger.error(f"ë°±ì—… ì‹¤íŒ¨: {e}")
            return ""
